{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this notebook is to setup a pipeline that can use parallelization and run all 4 codebases on multiple audio files. Results will be archived in a specific directory structure as discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code runs full 5 min audio files without any chunking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "import pandas as pd\n",
    "import os\n",
    "import dask\n",
    "import socket\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from  distributed import Client\n",
    "import subprocess\n",
    "from dask import delayed, compute\n",
    "import glob\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import mean_squared_error  \n",
    "import math  \n",
    "import warnings\n",
    "import pypandoc\n",
    "import jiwer\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "!module load openmind/ffmpeg/20160310 \n",
    "\n",
    "codebasenameoptions = ['yinruiqing', 'speechbox', 'ashraf', 'whisperx']  \n",
    "codebase_mapping_dict = {1: 'yinruiqing', 2: 'speechbox', 3: 'ashraf',4: 'whisperx'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#folder based-run of this pipeline \n",
    "#use glob itself\n",
    "\n",
    "box_set_9 = [ '/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_2165-2465_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_2465-2765_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_9365-9665_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/40_JC_Recording1-LR_2662-2962_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/40_JC_Recording1-LR_2962-3262_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/40_JC_Recording2-LR_22826-23126_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_2244-2544_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_3144-3444_CT.wav',\n",
    "'/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_9444-9744_CT.wav'\n",
    "]\n",
    "\n",
    "childes_random_10 = ['/om/user/arjunp/rawAudioFiles/Ethan_021005_first5.wav', '/om/user/arjunp/rawAudioFiles/Lily_030725_first5.wav', '/om/user/arjunp/rawAudioFiles/William_030011_first5.wav', '/om/user/arjunp/rawAudioFiles/Naima_020720_first5.wav', '/om/user/arjunp/rawAudioFiles/Naima_010801_first5.wav', '/om/user/arjunp/rawAudioFiles/William_011115_first5.wav', '/om/user/arjunp/rawAudioFiles/Violet_030119_first5.wav',   '/om/user/arjunp/rawAudioFiles/Ethan_020208_first5.wav', '/om/user/arjunp/rawAudioFiles/Alex_010526_first5.wav', '/om/user/arjunp/rawAudioFiles/Lily_040002_first5.wav']\n",
    "AUDIO_FILE_NAMES = childes_random_10 + box_set_9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/om/user/arjunp/rawAudioFiles/Ethan_021005_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/first_min_030327.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_3144-3444_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Lily_030725_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_2465-2765_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/William_030011_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/40_JC_Recording2-LR_22826-23126_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Naima_020720_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_9444-9744_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Naima_010801_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/William_011115_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Violet_030119_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_9365-9665_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/afjiv.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Alex_030119_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/030327.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Ethan_020208_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Alex_010526_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/34_KS_Recording4-LR_2165-2465_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/85_NA_Recording1-LR_2244-2544_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/40_JC_Recording1-LR_2662-2962_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/third_min_030327.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/Lily_040002_first5.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/40_JC_Recording1-LR_2962-3262_CT.wav',\n",
       " '/om/user/arjunp/rawAudioFiles/second_min_030327.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glob.glob('/om/user/arjunp/rawAudioFiles/*.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codebaseCommand(codebase_id, audiopath, specific_csv_path,notes, params):\n",
    "    #print(type(params))\n",
    "    # TO DO: parse kwargs and pass them to the command and then update the cb scripts; and then change to argparse inside\n",
    "    extra_args = []\n",
    "    for key, value in params.items():\n",
    "        extra_args.append('-'+key)\n",
    "        extra_args.append(value)\n",
    "\n",
    "\n",
    "    if codebase_id == 1:\n",
    "        command = ['python', 'yinruiqing_trial.py', audiopath,specific_csv_path] + extra_args\n",
    "        #print(command)\n",
    "        \n",
    "    elif codebase_id == 2:\n",
    "        command = ['python', 'speechbox_trial.py', audiopath,specific_csv_path]  \n",
    "         \n",
    "    elif codebase_id == 3:\n",
    "        command = ['python', '/om/user/arjunp/ashraf_repo/whisper-diarization/diarize.py','-a',audiopath, '--whisper-model', 'small.en'] \n",
    "        srtpath = audiopath[:-4] +\".srt\" \n",
    "         \n",
    "        command2 = ['python', '/om/user/arjunp/process_ashraf_output.py', srtpath,specific_csv_path]  \n",
    "    else:\n",
    "        command = ['python', 'whisperx_demo.py',audiopath,specific_csv_path]\n",
    "\n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "\n",
    "    if codebase_id == 3:\n",
    "        result2 = subprocess.run(command2, capture_output=True, text=True)\n",
    "        return result, result2\n",
    "    else: \n",
    "        return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runCodebase(codebase_id, audiofilepaths, unixtime ,  notes, params):\n",
    "\n",
    "    result_list = []\n",
    "\n",
    "    codebasenameoptions = ['yinruiqing', 'speechbox', 'ashraf', 'whisperx']\n",
    "    codebasename = codebasenameoptions[codebase_id-1]\n",
    "\n",
    "    if codebase_id==1:\n",
    "        cluster = SLURMCluster(cores=8,\n",
    "                       processes=1,\n",
    "                       memory=\"24GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'export MKL_THREADING_LAYER=GNU',\n",
    "                        'conda activate torch_gpu'\n",
    "                                              ],\n",
    "                       job_extra_directives=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "        cluster.scale(1)\n",
    "        #cluster.adapt()\n",
    "        client = Client(cluster)\n",
    "\n",
    "    elif codebase_id ==2:\n",
    "       \n",
    "        cluster = SLURMCluster(cores=8,\n",
    "                       processes=2,\n",
    "                       memory=\"32GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"02:00:00\",\n",
    "                       queue=\"cpl\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'export MKL_THREADING_LAYER=GNU',\n",
    "                        'conda activate torch_gpu'\n",
    "                                              ],\n",
    "                       job_extra_directives=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "        cluster.scale(1)\n",
    "        #cluster.adapt()\n",
    "        client = Client(cluster)\n",
    "\n",
    "    elif codebase_id==3:\n",
    "        cluster = SLURMCluster(cores=8, \n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",  \n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"cpl\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind8/ffmpeg/2023-05' , 'source ~/.bashrc',\n",
    "                        'conda activate codebase3' \n",
    "                        #'cd /om/user/arjunp/ashraf_repo/whisper-diarization'\n",
    "                                              ],\n",
    "                       job_extra_directives=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "        cluster.scale(1)\n",
    "        #cluster.adapt()\n",
    "        client = Client(cluster)\n",
    "\n",
    "    else: \n",
    "        cluster = SLURMCluster(cores=8,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind8/cuda/12.1',                 \n",
    "                        'module load openmind8/cudnn/8.8.1-cuda12'  ,\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'conda activate whisperx'\n",
    "                                              ],\n",
    "                       job_extra_directives=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "        cluster.scale(1)\n",
    "        #cluster.adapt()\n",
    "        client = Client(cluster)\n",
    "\n",
    "    #print(\"set up cluster for cb\", codebase_id )\n",
    "\n",
    "    for audiopath in audiofilepaths:\n",
    "\n",
    "        # -------- CREATING FILE STRUCTURE ---------------\n",
    "        filename = os.path.basename(audiopath)[:-4]\n",
    "        #unixtime = str(round(time.time()))\n",
    "        unix_level = os.path.join('/om/user/arjunp/pipelineOutput',unixtime)\n",
    "         \n",
    "        if not os.path.exists(unix_level):\n",
    "            os.makedirs(unix_level)\n",
    "        \n",
    "        cb_level = os.path.join(unix_level,codebasename)\n",
    "        \n",
    "        if not os.path.exists(cb_level):\n",
    "            os.makedirs(cb_level)\n",
    "            #print(\"created folder for\", codebasename)\n",
    "\n",
    "        csv_to_save = filename+\".csv\"\n",
    "        specific_path = os.path.join(cb_level, csv_to_save)\n",
    "\n",
    "\n",
    "        future  = client.submit(codebaseCommand,codebase_id,audiopath,specific_path,notes,params)  \n",
    "        result  = future.result()\n",
    "        result_list.append(result)\n",
    "        print(\"Ran codebase\", codebase_id, \"on\", filename)\n",
    "\n",
    "         # -------- CREATING METADATA JSON ---------------\n",
    "        dictionary = {\n",
    "                \"csvname\": csv_to_save,\n",
    "                \"codebase\":  codebasename,\n",
    "                \"codebase_id\": codebase_id,\n",
    "                \"audiofile\": filename,\n",
    "                \"full_csv_path\" : specific_path,\n",
    "                \"unix_time\":unixtime,\n",
    "                \"parameters\" : params,\n",
    "                \"notes\": notes}\n",
    " \n",
    "\n",
    "        jsonpath = os.path.join(cb_level,  filename+\".json\")\n",
    "\n",
    "        if os.path.exists(jsonpath):\n",
    "            #read existing file and append new data\n",
    "            with open(jsonpath,\"r\") as f:\n",
    "                loaded = json.load(f)\n",
    "            loaded.append(dictionary)\n",
    "        else:\n",
    "            #create new json\n",
    "            loaded = [dictionary]\n",
    "\n",
    "        #overwrite/create file\n",
    "        with open(jsonpath,\"w\") as f:\n",
    "            json.dump(loaded,f,indent=4)\n",
    "    print(\"Closing cluster normally.\")\n",
    "    #client.close() \n",
    "    #cluster.close()\n",
    "    \n",
    "    return result_list\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The block below actually runs all the codebases on all the audiofiles through dask."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ran codebase 1 on Ethan_021005_first5\n",
      "Ran codebase 1 on Lily_030725_first5\n",
      "Ran codebase 1 on William_030011_first5\n",
      "Ran codebase 1 on Naima_020720_first5\n",
      "Ran codebase 1 on Naima_010801_first5\n",
      "Ran codebase 1 on William_011115_first5\n",
      "Ran codebase 1 on Violet_030119_first5\n",
      "Ran codebase 1 on Ethan_020208_first5\n",
      "Ran codebase 1 on Alex_010526_first5\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#beam_sizes = [2,4,8,16,32]  \n",
    "#patience_factors = [0.5,1,2,4]\n",
    "beam_sizes = [1,5] \n",
    "#temperatures = [0,0.25,0.5,0.75]\n",
    "\n",
    "audiofilepaths = [os.path.join('/om/user/arjunp/rawAudioFiles', os.path.basename(name_of_audio)) for name_of_audio in AUDIO_FILE_NAMES]\n",
    "#timestamps_from_this_run = []\n",
    "unixtimestamp = str(round(time.time()))\n",
    "#timestamps_from_this_run = [unixtimestamp+\"temperature\"+str(beam)  for beam in temperatures]\n",
    "notes=\"experimenting with  prompt (not initial_prompt) on  small.en\"\n",
    "#list_of_args = [(1, audiofilepaths,unixtimestamp+\"beam\"+str(beam),notes,{\"beam_size\": str(beam), \"temperature\": \"0\"}) for beam in beam_sizes]\n",
    "\n",
    "#list_of_args = [(1, audiofilepaths,unixtimestamp+\"temp0.75beam2\",notes,{ \"temperature\": \" 0.75\", 'beam_size':'2'}) ]\n",
    "list_of_args = [(1, audiofilepaths,unixtimestamp,notes,{ \"temperature\": \" 0\",  \"prompt\":\"context is child-parent interaction\"})  ]\n",
    "with Pool(processes=8) as pool: \n",
    "    poolresult = pool.starmap(runCodebase, list_of_args)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set up cluster for cb 1\n",
      "created folder for yinruiqing\n",
      "Ran codebase 1 on 34_KS_Recording4-LR_2165-2465_CT\n",
      "Ran codebase 1 on 34_KS_Recording4-LR_2465-2765_CT\n",
      "Ran codebase 1 on 34_KS_Recording4-LR_9365-9665_CT\n",
      "Ran codebase 1 on 40_JC_Recording1-LR_2662-2962_CT\n",
      "Ran codebase 1 on 40_JC_Recording1-LR_2962-3262_CT\n",
      "Ran codebase 1 on 40_JC_Recording2-LR_22826-23126_CT\n",
      "Ran codebase 1 on 85_NA_Recording1-LR_2244-2544_CT\n",
      "Ran codebase 1 on 85_NA_Recording1-LR_3144-3444_CT\n",
      "Ran codebase 1 on 85_NA_Recording1-LR_9444-9744_CT\n",
      "finished beam size 2\n",
      "set up cluster for cb 1\n",
      "created folder for yinruiqing\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:15\u001b[0m\n",
      "File \u001b[0;32m/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/multiprocessing/pool.py:375\u001b[0m, in \u001b[0;36mPool.starmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstarmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, iterable, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    370\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;124;03m    Like `map()` method but the elements of the `iterable` are expected to\u001b[39;00m\n\u001b[1;32m    372\u001b[0m \u001b[38;5;124;03m    be iterables as well and will be unpacked as arguments. Hence\u001b[39;00m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;124;03m    `func` and (a, b) becomes func(a, b).\u001b[39;00m\n\u001b[1;32m    374\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_async(func, iterable, starmapstar, chunksize)\u001b[38;5;241m.\u001b[39mget()\n",
      "File \u001b[0;32m/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/multiprocessing/pool.py:768\u001b[0m, in \u001b[0;36mApplyResult.get\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    769\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mready():\n\u001b[1;32m    770\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m\n",
      "File \u001b[0;32m/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/multiprocessing/pool.py:765\u001b[0m, in \u001b[0;36mApplyResult.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwait\u001b[39m(\u001b[38;5;28mself\u001b[39m, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 765\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event\u001b[38;5;241m.\u001b[39mwait(timeout)\n",
      "File \u001b[0;32m/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/threading.py:622\u001b[0m, in \u001b[0;36mEvent.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    620\u001b[0m signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flag\n\u001b[1;32m    621\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m signaled:\n\u001b[0;32m--> 622\u001b[0m     signaled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cond\u001b[38;5;241m.\u001b[39mwait(timeout)\n\u001b[1;32m    623\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m signaled\n",
      "File \u001b[0;32m/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         waiter\u001b[38;5;241m.\u001b[39macquire()\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# beam_sizes = [2,4,8,16,32]  \n",
    "\n",
    "beam_sizes = [5]  \n",
    "\n",
    "AUDIO_FILE_NAMES = box_set_9\n",
    "audiofilepaths = [os.path.join('/om/user/arjunp/rawAudioFiles', os.path.basename(name_of_audio)) for name_of_audio in AUDIO_FILE_NAMES]\n",
    "timestamps_from_this_run = []\n",
    "\n",
    "for i in beam_sizes:\n",
    "    unixtimestamp = str(round(time.time()))\n",
    "    beamvalue = str(i)\n",
    "    timestamps_from_this_run.append(unixtimestamp)\n",
    " \n",
    "#list_of_args = [(i+1, audiofilepaths,unixtimestamp) for i in range(4)]\n",
    "    notes=\"\"\n",
    "    params = {\"beam_size\": beamvalue, \"temperature\": \"0\"}\n",
    "    list_of_args = [(i+1, audiofilepaths,unixtimestamp,notes,params) for i in range(4)]\n",
    " \n",
    "    with Pool(processes=14) as pool: \n",
    "        poolresult = pool.starmap(runCodebase, list_of_args)\n",
    "    print(\"finished beam size\", i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../home/arjunp/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n",
      "Traceback (most recent call last):\n",
      "  File \"/weka/scratch/weka/cpl/arjunp/yinruiqing_trial.py\", line 22, in <module>\n",
      "    parser.add_argument('audio_file_path', type=str,   required=True)\n",
      "  File \"/home/arjunp/.conda/envs/torch_gpu/lib/python3.9/argparse.py\", line 1405, in add_argument\n",
      "    kwargs = self._get_positional_kwargs(*args, **kwargs)\n",
      "  File \"/home/arjunp/.conda/envs/torch_gpu/lib/python3.9/argparse.py\", line 1521, in _get_positional_kwargs\n",
      "    raise TypeError(msg)\n",
      "TypeError: 'required' is an invalid argument for positionals\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(poolresult[0][0].stderr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time to round up all the json files created to make one big json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def updateMyJson():\n",
    "    jsons_to_combine=[]\n",
    "\n",
    "    for filename in glob.glob('pipelineOutput/**/*.json', recursive=True):\n",
    "        if  filename !=\"pipelineOutput/metadata.json\":\n",
    "            jsons_to_combine.append(filename)   \n",
    "\n",
    "\n",
    "    combined_data = []\n",
    "\n",
    "    # Iterate over each JSON file \n",
    "    for file_path in jsons_to_combine:\n",
    "        with open(file_path, 'r') as f:\n",
    "            data = json.load(f)\n",
    "            combined_data.append(data)\n",
    "\n",
    "    # Write the combined data to a new JSON file\n",
    "    with open('pipelineOutput/metadata.json', 'w') as f:\n",
    "        json.dump(combined_data, f, indent=4)\n",
    "\n",
    "    print(\"All JSON files have been combined into 'metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All JSON files have been combined into 'metadata.json\n"
     ]
    }
   ],
   "source": [
    "updateMyJson()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
