{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5cbc20f",
   "metadata": {},
   "source": [
    "### Aim \n",
    "Running all 4 codebases on 1 of the recordings from Box, using dask\n",
    "### Recording\n",
    "34_KS_Recording4-LR_2165-2465_CT\n",
    "### Codebases\n",
    "Codebase 1: yinruiqing https://github.com/yinruiqing/pyannote-whisper/ <br />\n",
    "Codebase 2: speechbox https://github.com/huggingface/speechbox/ <br />\n",
    "Codebase 3: ashraf https://github.com/MahmoudAshraf97/whisper-diarization <br />\n",
    "Codebase 4: whisperx https://github.com/m-bain/whisperX <br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebee8c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import dask\n",
    "import socket\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from  distributed import Client\n",
    "import subprocess\n",
    "!module load openmind/ffmpeg/20160310 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e563a69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio split into 1-minute segments successfully!\n"
     ]
    }
   ],
   "source": [
    "# Load the WAV file\n",
    "audio = AudioSegment.from_wav(\"rawAudioFiles/34_KS_Recording4-LR_2165-2465_CT.wav\")\n",
    "directory_path = os.path.join(\"chunks_\"+\"34_KS_Recording4-LR_2165-2465_CT\")\n",
    "os.makedirs(directory_path, exist_ok=True)\n",
    "# Length of one minute in milliseconds\n",
    "one_minute = 60 * 1000\n",
    "\n",
    "# Split and save each 1-minute segment\n",
    "for i in range(5):\n",
    "    start_time = i * one_minute\n",
    "    end_time = (i + 1) * one_minute if i < 4 else len(audio)\n",
    "    segment = audio[start_time:end_time]\n",
    "    name_of_file = f\"minute_{i + 1}.wav\"\n",
    "    path_to_file = os.path.join(directory_path, name_of_file)\n",
    "    segment.export(path_to_file, format=\"wav\")\n",
    "\n",
    "print(\"Audio split into 1-minute segments successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1ab6ef4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 41739 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cluster = SLURMCluster(cores=8,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind8/cuda/12.1',                 \n",
    "                        'module load openmind8/cudnn/8.8.1-cuda12'  ,\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'conda activate whisperx'\n",
    "                                              ],\n",
    "                       job_extra=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "cluster.scale(5)\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5b6ccff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          37461657    normal     bash   arjunp  R       6:21      1 node091\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u arjunp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fad8ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!scancel 37451543 37451544 37451545"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9460f3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cb1_script(audiopath):\n",
    "     \n",
    "    command = ['python', 'yinruiqing_trial.py', audiopath]  \n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "     \n",
    "    print(\"STDOUT:\", result.stdout)\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "    return result\n",
    "\n",
    "def run_cb2_script(audiopath):\n",
    "     \n",
    "    command = ['python', 'speechbox_trial.py', audiopath]  \n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "     \n",
    "    print(\"STDOUT:\", result.stdout)\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "    return result\n",
    "\n",
    "def run_cb3_script(audiopath):\n",
    "     \n",
    "    command = ['python', '/om/user/arjunp/ashraf_repo/whisper-diarization/diarize.py','-a',audiopath] \n",
    "    srtpath = audiopath[:-4] +\".srt\"\n",
    "    command2 = ['python', '/om/user/arjunp/process_ashraf_output.py', srtpath]  \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "    result2 = subprocess.run(command2, capture_output=True, text=True)\n",
    "     \n",
    "    print(\"STDOUT:\", result.stdout)\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "    return result\n",
    "\n",
    "def run_whisperx(audiopath):\n",
    "     \n",
    "    command = ['python', 'whisperx_demo.py',audiopath]  \n",
    "    \n",
    "    result = subprocess.run(command, capture_output=True, text=True)\n",
    "     \n",
    "    print(\"STDOUT:\", result.stdout)\n",
    "    print(\"STDERR:\", result.stderr)\n",
    "    return result\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dc2c2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_list = []\n",
    "for filename in os.listdir('chunks_34_KS_Recording4-LR_2165-2465_CT'):\n",
    "    audiopath = os.path.join('chunks_34_KS_Recording4-LR_2165-2465_CT', filename)\n",
    "    future  = client.submit(run_whisperx,audiopath)  \n",
    "    result  = future.result()\n",
    "    result_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31241b8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6137235f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/weka/scratch/weka/cpl/arjunp/whisperx_demo.py\", line 1, in <module>\n",
      "    import whisperx\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/whisperx/__init__.py\", line 1, in <module>\n",
      "    from .transcribe import load_model\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/whisperx/transcribe.py\", line 10, in <module>\n",
      "    from .asr import load_model\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/whisperx/asr.py\", line 13, in <module>\n",
      "    from .vad import load_vad_model, merge_chunks\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/whisperx/vad.py\", line 9, in <module>\n",
      "    from pyannote.audio import Model\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/pyannote/audio/__init__.py\", line 29, in <module>\n",
      "    from .core.inference import Inference\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/pyannote/audio/core/inference.py\", line 33, in <module>\n",
      "    from pyannote.core import Segment, SlidingWindow, SlidingWindowFeature\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/pyannote/core/__init__.py\", line 48, in <module>\n",
      "    from .notebook import notebook\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/pyannote/core/notebook.py\", line 111, in <module>\n",
      "    import matplotlib\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/matplotlib/__init__.py\", line 1270, in <module>\n",
      "    rcParams['backend'] = os.environ.get('MPLBACKEND')\n",
      "  File \"/home/arjunp/.conda/envs/whisperx/lib/python3.10/site-packages/matplotlib/__init__.py\", line 738, in __setitem__\n",
      "    raise ValueError(f\"Key {key}: {ve}\") from None\n",
      "ValueError: Key backend: 'module://matplotlib_inline.backend_inline' is not a valid value for backend; supported values are ['gtk3agg', 'gtk3cairo', 'gtk4agg', 'gtk4cairo', 'macosx', 'nbagg', 'notebook', 'qtagg', 'qtcairo', 'qt5agg', 'qt5cairo', 'tkagg', 'tkcairo', 'webagg', 'wx', 'wxagg', 'wxcairo', 'agg', 'cairo', 'pdf', 'pgf', 'ps', 'svg', 'template']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(result.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2ddb528e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codebase1Run():\n",
    "    cluster = SLURMCluster(cores=4,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'export MKL_THREADING_LAYER=GNU',\n",
    "                        'conda activate torch_gpu'\n",
    "                                              ],\n",
    "                       job_extra=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "    cluster.scale(5)\n",
    "    client = Client(cluster)\n",
    "    result_list = []\n",
    "    for filename in os.listdir('chunks_34_KS_Recording4-LR_2165-2465_CT'):\n",
    "        audiopath = os.path.join('chunks_34_KS_Recording4-LR_2165-2465_CT', filename)\n",
    "        future  = client.submit(run_cb1_script,audiopath)  \n",
    "        result  = future.result()\n",
    "        result_list.append(result)\n",
    "    cluster.close()\n",
    "    client.close()\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3df4312",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codebase2Run():\n",
    "    cluster = SLURMCluster(cores=4,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'export MKL_THREADING_LAYER=GNU',\n",
    "                        'conda activate torch_gpu'\n",
    "                                              ],\n",
    "                       job_extra=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "    cluster.scale(5)\n",
    "    client = Client(cluster)\n",
    "    result_list = []\n",
    "    for filename in os.listdir('chunks_34_KS_Recording4-LR_2165-2465_CT'):\n",
    "        audiopath = os.path.join('chunks_34_KS_Recording4-LR_2165-2465_CT', filename)\n",
    "        future  = client.submit(run_cb2_script,audiopath)  \n",
    "        result  = future.result()\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d3879070",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codebase3Run():\n",
    "    cluster = SLURMCluster(cores=4,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , 'source ~/.bashrc',\n",
    "                        'conda activate codebase3',\n",
    "                        'cd /om/user/arjunp/ashraf_repo/whisper-diarization'\n",
    "                                              ],\n",
    "                       job_extra=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "    cluster.scale(5)\n",
    "    client = Client(cluster)\n",
    "    result_list = []\n",
    "    main_directory = os.path.join('/om/user/arjunp','chunks_34_KS_Recording4-LR_2165-2465_CT')\n",
    "    for filename in os.listdir(main_directory):\n",
    "        audiopath = os.path.join(main_directory, filename)\n",
    "        future  = client.submit(run_cb3_script,audiopath)  \n",
    "        result  = future.result()\n",
    "        result_list.append(result)\n",
    "    client.close()\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be9c1d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def codebase4Run():\n",
    "    cluster = SLURMCluster(cores=4,\n",
    "                       processes=2,\n",
    "                       memory=\"16GB\",\n",
    "                       account=\"cpl\",\n",
    "                       walltime=\"01:00:00\",\n",
    "                       queue=\"normal\",\n",
    "                       job_script_prologue  =[\n",
    "                        'source /etc/profile.d/modules.sh' ,\n",
    "                        'module load openmind8/anaconda/3-2023.09-0',\n",
    "                        'module load openmind8/cuda/12.1',                 \n",
    "                        'module load openmind8/cudnn/8.8.1-cuda12'  ,\n",
    "                        'module load openmind/gcc/11.1.0',\n",
    "                        'module load openmind/ffmpeg/20160310' , \n",
    "                        'source ~/.bashrc',\n",
    "                        'conda activate whisperx'\n",
    "                                              ],\n",
    "                       job_extra=['--gres=gpu:QUADRORTX6000:1'] \n",
    "                       )\n",
    "    cluster.scale(5)\n",
    "    client= Client(cluster)\n",
    "    \n",
    "    result_list = []\n",
    "    for filename in os.listdir('chunks_34_KS_Recording4-LR_2165-2465_CT'):\n",
    "        audiopath = os.path.join('chunks_34_KS_Recording4-LR_2165-2465_CT', filename)\n",
    "        future  = client.submit(run_whisperx,audiopath)  \n",
    "        result  = future.result()\n",
    "        result_list.append(result)\n",
    "    return result_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9e31af3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35445 instead\n",
      "  warnings.warn(\n",
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cb1res = codebase1Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "205d8e81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../home/arjunp/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cb1res[0].stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93242d90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 33037 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cb2res = codebase2Run()\n",
    "cb3res = codebase3Run()\n",
    "cb4res = codebase4Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0e79f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "cb2res = codebase2Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "467aa72f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arjunp/.local/lib/python3.11/site-packages/dask_jobqueue/core.py:266: FutureWarning: job_extra has been renamed to job_extra_directives. You are still using it (even if only set to []; please also check config files). If you did not set job_extra_directives yet, job_extra will be respected for now, but it will be removed in a future release. If you already set job_extra_directives, job_extra is ignored and you can remove it.\n",
      "  warnings.warn(warn, FutureWarning)\n",
      "/cm/shared/openmind8/anaconda/3-2023.09-0/lib/python3.11/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 35195 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "cb3res = codebase3Run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f08f9ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.5.4 to v2.3.3. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint ../../../../../home/arjunp/.cache/torch/pyannote/models--pyannote--segmentation/snapshots/c4c8ceafcbb3a7a280c2d357aee9fbc9b0be7f9b/pytorch_model.bin`\n",
      "\n",
      "Map:   0%|          | 0/1 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  1.20 examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00,  1.13 examples/s]\n",
      "\n",
      "Map:   0%|          | 0/1 [00:00<?, ? examples/s]\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 70.01 examples/s]\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Whisper did not predict an ending timestamp, which can happen if audio is cut off in the middle of a word. Also make sure WhisperTimeStampLogitsProcessor was used during generation.\n",
      "Traceback (most recent call last):\n",
      "  File \"/weka/scratch/weka/cpl/arjunp/speechbox_trial.py\", line 48, in <module>\n",
      "    out = pipeline1(np.array (sample[\"audio\"]))\n",
      "  File \"/home/arjunp/.conda/envs/torch_gpu/lib/python3.9/site-packages/speechbox/diarize.py\", line 153, in __call__\n",
      "    upto_idx = np.argmin(np.abs(end_timestamps - end_time))\n",
      "TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cb2res[4].stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "88c5c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected model is a bag of 1 models. You will see that many progress bars per track.\n",
      "Separated tracks will be stored in /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/htdemucs\n",
      "Separating track /om/user/arjunp/chunks_34_KS_Recording4-LR_2165-2465_CT/minute_2.wav\n",
      "GPU Name: Quadro RTX 6000\n",
      "CUDA Compute Capability: (7, 5)\n",
      "Your GPU supports efficient float16 computation.\n",
      "Model was trained with pyannote.audio 0.0.1, yours is 3.1.1. Bad things might happen unless you revert pyannote.audio to 0.x.\n",
      "Model was trained with torch 1.10.0+cu102, yours is 2.1.2+cu121. Bad things might happen unless you revert torch to 1.x.\n",
      "[NeMo I 2024-07-28 22:45:26 msdd_models:1092] Loading pretrained diar_msdd_telephonic model from NGC\n",
      "[NeMo I 2024-07-28 22:45:26 cloud:58] Found existing object /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2024-07-28 22:45:26 cloud:64] Re-using file from: /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo\n",
      "[NeMo I 2024-07-28 22:45:26 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-07-28 22:45:27 features:289] PADDING: 16\n",
      "[NeMo I 2024-07-28 22:45:27 features:289] PADDING: 16\n",
      "[NeMo I 2024-07-28 22:45:28 save_restore_connector:249] Model EncDecDiarLabelModel was successfully restored from /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/diar_msdd_telephonic/3c3697a0a46f945574fa407149975a13/diar_msdd_telephonic.nemo.\n",
      "[NeMo I 2024-07-28 22:45:28 features:289] PADDING: 16\n",
      "[NeMo I 2024-07-28 22:45:29 clustering_diarizer:127] Loading pretrained vad_multilingual_marblenet model from NGC\n",
      "[NeMo I 2024-07-28 22:45:29 cloud:58] Found existing object /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2024-07-28 22:45:29 cloud:64] Re-using file from: /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo\n",
      "[NeMo I 2024-07-28 22:45:29 common:913] Instantiating model from pre-trained checkpoint\n",
      "[NeMo I 2024-07-28 22:45:29 features:289] PADDING: 16\n",
      "[NeMo I 2024-07-28 22:45:29 save_restore_connector:249] Model EncDecClassificationModel was successfully restored from /home/arjunp/.cache/torch/NeMo/NeMo_1.20.0/vad_multilingual_marblenet/670f425c7f186060b7a7268ba6dfacb2/vad_multilingual_marblenet.nemo.\n",
      "[NeMo I 2024-07-28 22:45:29 msdd_models:864] Multiscale Weights: [1, 1, 1, 1, 1]\n",
      "[NeMo I 2024-07-28 22:45:29 msdd_models:865] Clustering Parameters: {\n",
      "        \"oracle_num_speakers\": false,\n",
      "        \"max_num_speakers\": 8,\n",
      "        \"enhanced_count_thres\": 80,\n",
      "        \"max_rp_threshold\": 0.25,\n",
      "        \"sparse_search_volume\": 30,\n",
      "        \"maj_vote_spk_count\": false,\n",
      "        \"chunk_cluster_count\": 50,\n",
      "        \"embeddings_per_chunk\": 10000\n",
      "    }\n",
      "[NeMo I 2024-07-28 22:45:29 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-07-28 22:45:29 clustering_diarizer:309] Split long audio file to avoid CUDA memory issue\n",
      "[NeMo I 2024-07-28 22:45:33 classification_models:272] Perform streaming frame-level VAD\n",
      "[NeMo I 2024-07-28 22:45:33 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:33 collections:302] Dataset loaded with 2 items, total duration of  0.02 hours.\n",
      "[NeMo I 2024-07-28 22:45:33 collections:304] # 2 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:33 clustering_diarizer:250] Generating predictions with overlapping input segments\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:262] Converting frame level prediction to speech/no-speech segment in start and end times format.\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale0, /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale0.json\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-07-28 22:45:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:302] Dataset loaded with 12 items, total duration of  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:304] # 12 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:389] Saved embedding files to /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale1, /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale1.json\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-07-28 22:45:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:302] Dataset loaded with 12 items, total duration of  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:304] # 12 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:389] Saved embedding files to /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale2, /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale2.json\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-07-28 22:45:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:302] Dataset loaded with 13 items, total duration of  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:304] # 13 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:389] Saved embedding files to /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale3, /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale3.json\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-07-28 22:45:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:302] Dataset loaded with 15 items, total duration of  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:304] # 15 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:389] Saved embedding files to /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:287] Subsegmentation for embedding extraction: scale4, /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale4.json\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:343] Extracting embeddings for Diarization\n",
      "[NeMo I 2024-07-28 22:45:34 collections:301] Filtered duration for loading collection is  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:302] Dataset loaded with 20 items, total duration of  0.00 hours.\n",
      "[NeMo I 2024-07-28 22:45:34 collections:304] # 20 files loaded accounting to # 1 labels\n",
      "[NeMo I 2024-07-28 22:45:34 clustering_diarizer:389] Saved embedding files to /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings\n",
      "[NeMo I 2024-07-28 22:45:35 clustering_diarizer:464] Outputs are saved in /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs directory\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:960] Loading embedding pickle file of scale:0 at /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale0_embeddings.pkl\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:960] Loading embedding pickle file of scale:1 at /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale1_embeddings.pkl\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:960] Loading embedding pickle file of scale:2 at /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale2_embeddings.pkl\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:960] Loading embedding pickle file of scale:3 at /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale3_embeddings.pkl\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:960] Loading embedding pickle file of scale:4 at /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/embeddings/subsegments_scale4_embeddings.pkl\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:938] Loading cluster label file from /weka/scratch/weka/cpl/arjunp/ashraf_repo/whisper-diarization/temp_outputs/speaker_outputs/subsegments_scale4_cluster.label\n",
      "[NeMo I 2024-07-28 22:45:35 collections:617] Filtered duration for loading collection is 0.000000.\n",
      "[NeMo I 2024-07-28 22:45:35 collections:620] Total 1 session files loaded accounting to # 1 audio clips\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:1403]      [Threshold: 0.7000] [use_clus_as_main=False] [diar_window=50]\n",
      "[NeMo I 2024-07-28 22:45:35 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-07-28 22:45:35 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-07-28 22:45:35 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-07-28 22:45:35 speaker_utils:93] Number of files to diarize: 1\n",
      "[NeMo I 2024-07-28 22:45:35 msdd_models:1431]   \n",
      "    \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(cb3res[0].stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "28b98da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             JOBID PARTITION     NAME     USER ST       TIME  NODES NODELIST(REASON)\r\n",
      "          37461680    normal dask-wor   arjunp  R      48:59      1 node078\r\n",
      "          37461681    normal dask-wor   arjunp  R      48:59      1 node078\r\n",
      "          37461682    normal dask-wor   arjunp  R      48:59      1 node078\r\n",
      "          37461932    normal dask-wor   arjunp  R       8:49      1 node078\r\n",
      "          37461933    normal dask-wor   arjunp  R       8:49      1 node079\r\n",
      "          37461934    normal dask-wor   arjunp  R       8:49      1 node079\r\n",
      "          37461811    normal dask-wor   arjunp  R      15:57      1 node091\r\n",
      "          37461812    normal dask-wor   arjunp  R      15:57      1 node091\r\n",
      "          37461813    normal dask-wor   arjunp  R      15:57      1 node091\r\n",
      "          37461657    normal     bash   arjunp  R    1:01:24      1 node091\r\n"
     ]
    }
   ],
   "source": [
    "!squeue -u arjunp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48576d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
